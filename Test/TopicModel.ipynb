{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling using HDP and LDA\n",
    "\n",
    "- Text Processing\n",
    "- Generating dictionary of vocabulary\n",
    "- Mapping corpus using dictionary\n",
    "- Training the Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%pip install \"gensim\" \"spacy\" \"pyLDAvis\" \n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import pyLDAvis.gensim_models\n",
    "#Import nltk stopwords and add custom stopwords that are likely to appear in news articles.\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"mrs\",\"ms\",\"say\",\"he\",\"mr\",\"she\",\"they\",\"company\"])\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing\n",
    "- Clean the article - Remove punctuation marks, special characters\n",
    "- Tokenize each article\n",
    "- Stem each token\n",
    "- Remove numberical tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>article_source_link</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017/2/7</td>\n",
       "      <td>http://abcnews.go.com/Politics/pence-break-tie...</td>\n",
       "      <td>Betsy DeVos Confirmed as Education Secretary, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michigan billionaire education activist Betsy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017/2/7</td>\n",
       "      <td>http://abcnews.go.com/Politics/wireStory/melan...</td>\n",
       "      <td>Melania Trump Says White House Could Mean Mill...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First lady Melania Trump has said little about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017/2/7</td>\n",
       "      <td>http://abcnews.go.com/Politics/wireStory/trump...</td>\n",
       "      <td>As Trump Fears Fraud, GOP Eliminates Election ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A House committee voted on Tuesday to eliminat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017/2/7</td>\n",
       "      <td>http://abcnews.go.com/Politics/appeals-court-d...</td>\n",
       "      <td>Appeals Court to Decide on Challenge to Trump'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This afternoon, three federal judges from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017/2/7</td>\n",
       "      <td>http://abcnews.go.com/US/23-states-winter-weat...</td>\n",
       "      <td>At Least 4 Tornadoes Reported in Southeast Lou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At least four tornadoes touched down in Louisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           publish_date                                article_source_link  \\\n",
       "article_id                                                                   \n",
       "1              2017/2/7  http://abcnews.go.com/Politics/pence-break-tie...   \n",
       "2              2017/2/7  http://abcnews.go.com/Politics/wireStory/melan...   \n",
       "3              2017/2/7  http://abcnews.go.com/Politics/wireStory/trump...   \n",
       "4              2017/2/7  http://abcnews.go.com/Politics/appeals-court-d...   \n",
       "5              2017/2/7  http://abcnews.go.com/US/23-states-winter-weat...   \n",
       "\n",
       "                                                        title subtitle  \\\n",
       "article_id                                                               \n",
       "1           Betsy DeVos Confirmed as Education Secretary, ...      NaN   \n",
       "2           Melania Trump Says White House Could Mean Mill...      NaN   \n",
       "3           As Trump Fears Fraud, GOP Eliminates Election ...      NaN   \n",
       "4           Appeals Court to Decide on Challenge to Trump'...      NaN   \n",
       "5           At Least 4 Tornadoes Reported in Southeast Lou...      NaN   \n",
       "\n",
       "                                                         text  \n",
       "article_id                                                     \n",
       "1           Michigan billionaire education activist Betsy ...  \n",
       "2           First lady Melania Trump has said little about...  \n",
       "3           A House committee voted on Tuesday to eliminat...  \n",
       "4           This afternoon, three federal judges from the ...  \n",
       "5           At least four tornadoes touched down in Louisi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"NewsArticles.csv\", encoding='unicode_escape',index_col=0)\n",
    "#drop all the unnamed columns\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use SPACY in this notebook for all the text processing related tasks. It is very powerful than NLTK. [Click here to learn more](https://spacy.io/usage/spacy-101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before loading the language you have to download it first. Go to your command prompt and execute this statement and \n",
    "# restart the kernel:\n",
    "# python -m spacy download en_core_web_sm\n",
    "#%pip install \"https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\"\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "#nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['text'].values.tolist()\n",
    "data1 = df['title'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Betsy DeVos Confirmed as Education Secretary, With Pence Casting Historic Tie-Breaking Vote'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "#data[0]\n",
    "data1[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations and others characters\n",
    "def preprocess(string):\n",
    "    return re.sub('[^\\w_\\s-]', ' ',str(string))\n",
    "\n",
    "data = list(map(preprocess,data))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4268/823511428.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlemma_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    994\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.set_annotations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\_parser_internals\\ner.pyx\u001b[0m in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.set_annotations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.SetEntsDefault.values\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\enum.py\u001b[0m in \u001b[0;36m__members__\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_member_names_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__members__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#data cleaning and lemmatization\n",
    "lemma_doc = []\n",
    "for datum in data:\n",
    "    sent = nlp(str(datum).lower())\n",
    "    text = []\n",
    "    for w in sent:\n",
    "        if not w.is_stop and not w.is_punct and not w.like_num and str(w) not in stop_words and (len(str(w)) > 4):\n",
    "            #adding the lematized version of the words\n",
    "            text.append(w.lemma_)\n",
    "    lemma_doc.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['michigan',\n",
       " 'billionaire',\n",
       " 'education',\n",
       " 'activist',\n",
       " 'betsy',\n",
       " 'devos',\n",
       " 'confirm',\n",
       " 'today',\n",
       " 'serve',\n",
       " 'secretary',\n",
       " 'education',\n",
       " 'president',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'president',\n",
       " 'penny',\n",
       " 'break',\n",
       " 'senate',\n",
       " 'senate',\n",
       " 'vote',\n",
       " 'devos',\n",
       " 'highly',\n",
       " 'contentious',\n",
       " 'nomination',\n",
       " 'afternoon',\n",
       " 'tally',\n",
       " 'split',\n",
       " 'evenly',\n",
       " 'require',\n",
       " 'penny',\n",
       " 'authority',\n",
       " 'president',\n",
       " 'upper',\n",
       " 'chamber',\n",
       " 'congress',\n",
       " 'break',\n",
       " 'impasse',\n",
       " 'president',\n",
       " 'break',\n",
       " 'confirm',\n",
       " 'cabinet',\n",
       " 'nominee',\n",
       " 'pence',\n",
       " 'count',\n",
       " 'vote',\n",
       " 'render',\n",
       " 'tally',\n",
       " 'democrats',\n",
       " 'stage',\n",
       " 'marathon',\n",
       " 'speech',\n",
       " 'lawmaker',\n",
       " 'take',\n",
       " 'floor',\n",
       " 'additional',\n",
       " 'republican',\n",
       " 'devos',\n",
       " 'block',\n",
       " 'confirmation',\n",
       " 'imagine',\n",
       " 'bad',\n",
       " 'choice',\n",
       " 'elizabeth',\n",
       " 'warren',\n",
       " 'letter',\n",
       " 'constituent',\n",
       " 'urge',\n",
       " 'devos',\n",
       " 'stir',\n",
       " 'vehement',\n",
       " 'opposition',\n",
       " 'teacher',\n",
       " 'union',\n",
       " 'senate',\n",
       " 'democrat',\n",
       " 'cite',\n",
       " 'concern',\n",
       " 'support',\n",
       " 'school',\n",
       " 'voucher',\n",
       " 'critic',\n",
       " 'believe',\n",
       " 'weaken',\n",
       " 'public',\n",
       " 'school',\n",
       " 'experience',\n",
       " 'attend',\n",
       " 'work',\n",
       " 'public',\n",
       " 'education',\n",
       " 'system',\n",
       " 'cite',\n",
       " 'familiarity',\n",
       " 'landmark',\n",
       " 'protect',\n",
       " 'education',\n",
       " 'need',\n",
       " 'disabled',\n",
       " 'child',\n",
       " '     ',\n",
       " 'pan',\n",
       " 'gaffe',\n",
       " 'confirmation',\n",
       " 'hearing',\n",
       " 'hedge',\n",
       " 'answer',\n",
       " 'school',\n",
       " 'say',\n",
       " 'need',\n",
       " 'state',\n",
       " 'wyome',\n",
       " 'defend',\n",
       " 'potential',\n",
       " 'grizzly',\n",
       " 'devos',\n",
       " 'nomination',\n",
       " 'average',\n",
       " 'negative',\n",
       " 'reaction',\n",
       " 'public',\n",
       " 'voter',\n",
       " 'flood',\n",
       " 'senate',\n",
       " 'phone',\n",
       " 'line',\n",
       " 'email',\n",
       " 'account',\n",
       " 'recent',\n",
       " 'week',\n",
       " 'chris',\n",
       " 'hollen',\n",
       " 'office',\n",
       " 'receive',\n",
       " 'call',\n",
       " 'devos',\n",
       " 'addition',\n",
       " 'entire',\n",
       " 'democratic',\n",
       " 'caucus',\n",
       " 'moderate',\n",
       " 'republican',\n",
       " 'susan',\n",
       " 'collin',\n",
       " 'maine',\n",
       " 'murkowski',\n",
       " 'alaska',\n",
       " 'announce',\n",
       " 'support',\n",
       " 'devos',\n",
       " 'speech',\n",
       " 'announce',\n",
       " 'opposition',\n",
       " 'collin',\n",
       " 'devos',\n",
       " 'focus',\n",
       " 'charter',\n",
       " 'voucher',\n",
       " 'raise',\n",
       " 'question',\n",
       " 'fully',\n",
       " 'appreciate',\n",
       " 'secretary',\n",
       " 'education',\n",
       " 'primary',\n",
       " 'focus',\n",
       " 'help',\n",
       " 'state',\n",
       " 'community',\n",
       " 'parent',\n",
       " 'teacher',\n",
       " 'school',\n",
       " 'board',\n",
       " 'member',\n",
       " 'administrator',\n",
       " 'strengthen',\n",
       " 'public',\n",
       " 'school',\n",
       " 'confirmation',\n",
       " 'senate',\n",
       " 'health',\n",
       " 'education',\n",
       " 'labor',\n",
       " 'pension',\n",
       " 'committee',\n",
       " 'vote',\n",
       " 'party',\n",
       " 'line',\n",
       " 'refer',\n",
       " 'devos',\n",
       " 'nomination',\n",
       " 'senate',\n",
       " 'morgan',\n",
       " 'winsor',\n",
       " 'contribute',\n",
       " 'report']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['michigan', 'billionaire', 'education', 'activist', 'betsy_devos', 'confirm', 'today', 'serve', 'secretary', 'education', 'president', 'trump', 'administration', 'president', 'penny', 'break', 'senate', 'senate', 'vote', 'devos', 'highly', 'contentious', 'nomination', 'afternoon', 'tally', 'split', 'evenly', 'require', 'penny', 'authority', 'president', 'upper', 'chamber', 'congress', 'break', 'impasse', 'president', 'break', 'confirm', 'cabinet_nominee', 'pence', 'count', 'vote', 'render', 'tally', 'democrats', 'stage', 'marathon', 'speech', 'lawmaker', 'take', 'floor', 'additional', 'republican', 'devos', 'block', 'confirmation', 'imagine', 'bad', 'choice', 'elizabeth_warren', 'letter', 'constituent', 'urge', 'devos', 'stir', 'vehement', 'opposition', 'teacher', 'union', 'senate', 'democrat', 'cite', 'concern', 'support', 'school', 'voucher', 'critic', 'believe', 'weaken', 'public', 'school', 'experience', 'attend', 'work', 'public', 'education', 'system', 'cite', 'familiarity', 'landmark', 'protect', 'education', 'need', 'disabled', 'child', '     ', 'pan', 'gaffe', 'confirmation_hearing', 'hedge', 'answer', 'school', 'say', 'need', 'state', 'wyome', 'defend', 'potential', 'grizzly', 'devos', 'nomination', 'average', 'negative', 'reaction', 'public', 'voter', 'flood', 'senate', 'phone', 'line', 'email_account', 'recent', 'week', 'chris', 'hollen', 'office', 'receive', 'call', 'devos', 'addition', 'entire', 'democratic', 'caucus', 'moderate', 'republican', 'susan_collin', 'maine', 'murkowski', 'alaska', 'announce', 'support', 'devos', 'speech', 'announce', 'opposition', 'collin', 'devos', 'focus', 'charter', 'voucher', 'raise', 'question', 'fully', 'appreciate', 'secretary', 'education', 'primary', 'focus', 'help', 'state', 'community', 'parent', 'teacher', 'school', 'board', 'member', 'administrator', 'strengthen', 'public', 'school', 'confirmation', 'senate', 'health', 'education', 'labor', 'pension', 'committee', 'vote', 'party', 'line', 'refer', 'devos', 'nomination', 'senate', 'morgan', 'winsor', 'contribute', 'report']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(lemma_doc, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[lemma_doc], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[lemma_doc[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Dictionary and Corpus needed for Topic Modeling\n",
    "- Word to IDs mapping\n",
    "- Bag of words of each document\n",
    "- corpus (cluster of Bag of words of all the documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(30441 unique tokens: ['     ', 'account', 'activist', 'addition', 'additional']...)\n"
     ]
    }
   ],
   "source": [
    "#Creates Word to IDs mapping\n",
    "word2id = corpora.Dictionary(lemma_doc)\n",
    "print(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus sample\n",
      "Word 0 :        || Number of occurences: 1\n",
      "Word 1 : account  || Number of occurences: 1\n",
      "Word 2 : activist  || Number of occurences: 1\n",
      "Word 3 : addition  || Number of occurences: 1\n",
      "Word 4 : additional  || Number of occurences: 1\n",
      "Word 5 : administration  || Number of occurences: 1\n",
      "Word 6 : administrator  || Number of occurences: 1\n",
      "Word 7 : afternoon  || Number of occurences: 1\n",
      "Word 8 : alaska  || Number of occurences: 1\n",
      "Word 9 : announce  || Number of occurences: 2\n",
      "Word 10 : answer  || Number of occurences: 1\n",
      "Word 11 : appreciate  || Number of occurences: 1\n",
      "Word 12 : attend  || Number of occurences: 1\n",
      "Word 13 : authority  || Number of occurences: 1\n",
      "Word 14 : average  || Number of occurences: 1\n",
      "Word 15 : bad  || Number of occurences: 1\n",
      "Word 16 : believe  || Number of occurences: 1\n",
      "Word 17 : betsy  || Number of occurences: 1\n",
      "Word 18 : billionaire  || Number of occurences: 1\n",
      "Word 19 : block  || Number of occurences: 1\n",
      "Word 20 : board  || Number of occurences: 1\n",
      "Word 21 : break  || Number of occurences: 3\n",
      "Word 22 : cabinet  || Number of occurences: 1\n",
      "Word 23 : call  || Number of occurences: 1\n",
      "Word 24 : caucus  || Number of occurences: 1\n",
      "Word 25 : chamber  || Number of occurences: 1\n",
      "Word 26 : charter  || Number of occurences: 1\n",
      "Word 27 : child  || Number of occurences: 1\n",
      "Word 28 : choice  || Number of occurences: 1\n",
      "Word 29 : chris  || Number of occurences: 1\n",
      "Word 30 : cite  || Number of occurences: 2\n",
      "Word 31 : collin  || Number of occurences: 2\n",
      "Word 32 : committee  || Number of occurences: 1\n",
      "Word 33 : community  || Number of occurences: 1\n",
      "Word 34 : concern  || Number of occurences: 1\n",
      "Word 35 : confirm  || Number of occurences: 2\n",
      "Word 36 : confirmation  || Number of occurences: 3\n",
      "Word 37 : congress  || Number of occurences: 1\n",
      "Word 38 : constituent  || Number of occurences: 1\n",
      "Word 39 : contentious  || Number of occurences: 1\n",
      "Word 40 : contribute  || Number of occurences: 1\n",
      "Word 41 : count  || Number of occurences: 1\n",
      "Word 42 : critic  || Number of occurences: 1\n",
      "Word 43 : defend  || Number of occurences: 1\n",
      "Word 44 : democrat  || Number of occurences: 1\n",
      "Word 45 : democratic  || Number of occurences: 1\n",
      "Word 46 : democrats  || Number of occurences: 1\n",
      "Word 47 : devos  || Number of occurences: 9\n",
      "Word 48 : disabled  || Number of occurences: 1\n",
      "Word 49 : education  || Number of occurences: 6\n",
      "Word 50 : elizabeth  || Number of occurences: 1\n",
      "Word 51 : email  || Number of occurences: 1\n",
      "Word 52 : entire  || Number of occurences: 1\n",
      "Word 53 : evenly  || Number of occurences: 1\n",
      "Word 54 : experience  || Number of occurences: 1\n",
      "Word 55 : familiarity  || Number of occurences: 1\n",
      "Word 56 : flood  || Number of occurences: 1\n",
      "Word 57 : floor  || Number of occurences: 1\n",
      "Word 58 : focus  || Number of occurences: 2\n",
      "Word 59 : fully  || Number of occurences: 1\n",
      "Word 60 : gaffe  || Number of occurences: 1\n",
      "Word 61 : grizzly  || Number of occurences: 1\n",
      "Word 62 : health  || Number of occurences: 1\n",
      "Word 63 : hearing  || Number of occurences: 1\n",
      "Word 64 : hedge  || Number of occurences: 1\n",
      "Word 65 : help  || Number of occurences: 1\n",
      "Word 66 : highly  || Number of occurences: 1\n",
      "Word 67 : hollen  || Number of occurences: 1\n",
      "Word 68 : imagine  || Number of occurences: 1\n",
      "Word 69 : impasse  || Number of occurences: 1\n",
      "Word 70 : labor  || Number of occurences: 1\n",
      "Word 71 : landmark  || Number of occurences: 1\n",
      "Word 72 : lawmaker  || Number of occurences: 1\n",
      "Word 73 : letter  || Number of occurences: 1\n",
      "Word 74 : line  || Number of occurences: 2\n",
      "Word 75 : maine  || Number of occurences: 1\n",
      "Word 76 : marathon  || Number of occurences: 1\n",
      "Word 77 : member  || Number of occurences: 1\n",
      "Word 78 : michigan  || Number of occurences: 1\n",
      "Word 79 : moderate  || Number of occurences: 1\n",
      "Word 80 : morgan  || Number of occurences: 1\n",
      "Word 81 : murkowski  || Number of occurences: 1\n",
      "Word 82 : need  || Number of occurences: 2\n",
      "Word 83 : negative  || Number of occurences: 1\n",
      "Word 84 : nomination  || Number of occurences: 3\n",
      "Word 85 : nominee  || Number of occurences: 1\n",
      "Word 86 : office  || Number of occurences: 1\n",
      "Word 87 : opposition  || Number of occurences: 2\n",
      "Word 88 : pan  || Number of occurences: 1\n",
      "Word 89 : parent  || Number of occurences: 1\n",
      "Word 90 : party  || Number of occurences: 1\n",
      "Word 91 : pence  || Number of occurences: 1\n",
      "Word 92 : penny  || Number of occurences: 2\n",
      "Word 93 : pension  || Number of occurences: 1\n",
      "Word 94 : phone  || Number of occurences: 1\n",
      "Word 95 : potential  || Number of occurences: 1\n",
      "Word 96 : president  || Number of occurences: 4\n",
      "Word 97 : primary  || Number of occurences: 1\n",
      "Word 98 : protect  || Number of occurences: 1\n",
      "Word 99 : public  || Number of occurences: 4\n",
      "Word 100 : question  || Number of occurences: 1\n",
      "Word 101 : raise  || Number of occurences: 1\n",
      "Word 102 : reaction  || Number of occurences: 1\n",
      "Word 103 : receive  || Number of occurences: 1\n",
      "Word 104 : recent  || Number of occurences: 1\n",
      "Word 105 : refer  || Number of occurences: 1\n",
      "Word 106 : render  || Number of occurences: 1\n",
      "Word 107 : report  || Number of occurences: 1\n",
      "Word 108 : republican  || Number of occurences: 2\n",
      "Word 109 : require  || Number of occurences: 1\n",
      "Word 110 : say  || Number of occurences: 1\n",
      "Word 111 : school  || Number of occurences: 5\n",
      "Word 112 : secretary  || Number of occurences: 2\n",
      "Word 113 : senate  || Number of occurences: 6\n",
      "Word 114 : serve  || Number of occurences: 1\n",
      "Word 115 : speech  || Number of occurences: 2\n",
      "Word 116 : split  || Number of occurences: 1\n",
      "Word 117 : stage  || Number of occurences: 1\n",
      "Word 118 : state  || Number of occurences: 2\n",
      "Word 119 : stir  || Number of occurences: 1\n",
      "Word 120 : strengthen  || Number of occurences: 1\n",
      "Word 121 : support  || Number of occurences: 2\n",
      "Word 122 : susan  || Number of occurences: 1\n",
      "Word 123 : system  || Number of occurences: 1\n",
      "Word 124 : take  || Number of occurences: 1\n",
      "Word 125 : tally  || Number of occurences: 2\n",
      "Word 126 : teacher  || Number of occurences: 2\n",
      "Word 127 : today  || Number of occurences: 1\n",
      "Word 128 : trump  || Number of occurences: 1\n",
      "Word 129 : union  || Number of occurences: 1\n",
      "Word 130 : upper  || Number of occurences: 1\n",
      "Word 131 : urge  || Number of occurences: 1\n",
      "Word 132 : vehement  || Number of occurences: 1\n",
      "Word 133 : vote  || Number of occurences: 3\n",
      "Word 134 : voter  || Number of occurences: 1\n",
      "Word 135 : voucher  || Number of occurences: 2\n",
      "Word 136 : warren  || Number of occurences: 1\n",
      "Word 137 : weaken  || Number of occurences: 1\n",
      "Word 138 : week  || Number of occurences: 1\n",
      "Word 139 : winsor  || Number of occurences: 1\n",
      "Word 140 : work  || Number of occurences: 1\n",
      "Word 141 : wyome  || Number of occurences: 1\n"
     ]
    }
   ],
   "source": [
    "# Creates bag of words and a corpus\n",
    "documents = lemma_doc\n",
    "corpus = [word2id.doc2bow(doc) for doc in documents]\n",
    "\n",
    "print('Corpus sample')\n",
    "sample = corpus[0]\n",
    "for i in range(len(sample)):\n",
    "    print('Word', sample[i][0], ':', word2id[sample[i][0]], ' || Number of occurences:', sample[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Dirichlet Processing\n",
    "This is kind of an unsupervised technique (Topic modeling is a unsupervised technique. Here the context is we don't decide the # of topics. In concept this is similar to Hierarchical cluster as don't choose the number of cluster before hand) as the model will identify the number of topics. Let's see what it will produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp = models.HdpModel(corpus,word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.009*trump + 0.006*people + 0.006*president + 0.005*state + 0.005*country + 0.004*government + 0.004*house + 0.003*report + 0.003*china + 0.003*year')\n",
      "(1, '0.007*trump + 0.006*people + 0.005*china + 0.004*president + 0.003*state + 0.003*country + 0.003*government + 0.003*house + 0.003*year + 0.003*report')\n",
      "(2, '0.008*china + 0.005*country + 0.005*people + 0.005*trump + 0.004*state + 0.004*chinese + 0.004*president + 0.003*government + 0.003*year + 0.003*group')\n",
      "(3, '0.006*china + 0.004*people + 0.004*country + 0.003*government + 0.003*percent + 0.002*report + 0.002*state + 0.002*chinese + 0.002*year + 0.002*find')\n",
      "(4, '0.003*trump + 0.002*state + 0.002*china + 0.002*german + 0.002*president + 0.002*world + 0.002*include + 0.002*country + 0.002*chinese + 0.002*chestnut')\n",
      "(5, '0.006*china + 0.003*trump + 0.003*president + 0.002*state + 0.002*country + 0.002*trade + 0.001*european + 0.001*island + 0.001*call + 0.001*minister')\n",
      "(6, '0.011*target + 0.009*attacker + 0.007*wound + 0.006*attack + 0.006*kill + 0.005*story + 0.003*shoot + 0.003*knife + 0.003*police + 0.002*officer')\n",
      "(7, '0.006*shark + 0.002*china + 0.002*beaver + 0.002*water + 0.002*great + 0.001*russia + 0.001*ukraine + 0.001*railway + 0.001*coral + 0.001*year')\n",
      "(8, '0.003*china + 0.002*trump + 0.002*state + 0.002*people + 0.002*region + 0.002*chinese + 0.001*report + 0.001*country + 0.001*government + 0.001*palestinian')\n",
      "(9, '0.002*jiaozi + 0.002*people + 0.002*trump + 0.002*chinese + 0.002*hospital + 0.001*country + 0.001*russian + 0.001*health + 0.001*brady + 0.001*china')\n",
      "(10, '0.006*happen + 0.006*cover + 0.004*attack + 0.004*china + 0.002*people + 0.002*police + 0.002*company + 0.002*foreign + 0.002*kill + 0.002*chinese')\n",
      "(11, '0.004*china + 0.002*accord + 0.002*afghanistan + 0.002*chinese + 0.002*report + 0.001*lavrov + 0.001*percent + 0.001*russia + 0.001*commission + 0.001*group')\n",
      "(12, '0.005*china + 0.002*economic + 0.002*policy + 0.002*investment + 0.002*growth + 0.002*percent + 0.002*reform + 0.002*market + 0.001*trump + 0.001*global')\n",
      "(13, '0.003*china + 0.001*trump + 0.001*court + 0.001*europe + 0.001*country + 0.001*factory + 0.001*technology + 0.001*investment + 0.001*daily + 0.001*international')\n",
      "(14, '0.004*china + 0.003*trade + 0.002*country + 0.002*chinese + 0.002*orchestra + 0.002*switzerland + 0.001*world + 0.001*president + 0.001*government + 0.001*european')\n",
      "(15, '0.002*country + 0.002*england + 0.002*people + 0.001*state + 0.001*poland + 0.001*route + 0.001*farmer + 0.001*german + 0.001*captain + 0.001*india')\n",
      "(16, '0.002*government + 0.001*scotland + 0.001*scottish + 0.001*people + 0.001*rhine + 0.001*trump + 0.001*country + 0.001*leave + 0.001*white + 0.001*policy')\n",
      "(17, '0.005*chinese + 0.003*investment + 0.002*company + 0.002*china + 0.002*takeover + 0.002*russian + 0.001*european + 0.001*growth + 0.001*europe + 0.001*foreign')\n",
      "(18, '0.001*hamster + 0.001*maize + 0.001*russia + 0.001*european + 0.001*office + 0.001*pellagra + 0.001*black + 0.001*group + 0.001*merkel + 0.001*press')\n",
      "(19, '0.002*trump + 0.002*attack + 0.002*museum + 0.001*report + 0.001*court + 0.001*president + 0.001*central + 0.001*shannon + 0.001*karen + 0.001*month')\n"
     ]
    }
   ],
   "source": [
    "hdp_topics = hdp.print_topics()\n",
    "for topic in hdp_topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDP model created: 20 Topics\n"
     ]
    }
   ],
   "source": [
    "print('HDP model created: '+str(len(hdp_topics))+' Topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Latent Dirichlet Allocation Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model = LdaModel(corpus=corpus, id2word=word2id, num_topics=5, random_state=42, update_every=1, chunksize=100, \n",
    "#                     passes=10, alpha='auto', per_word_topics=True)\n",
    "lda_model = LdaModel(corpus=corpus, id2word=word2id, num_topics=5, random_state=42, update_every=1, chunksize=100, \n",
    "                     passes=10, alpha='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x21d886f3e20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Article - Topic Distribution for first Article\n",
    "def get_article_topic_distribution(article):\n",
    "    return lda_model.get_document_topics(article)\n",
    "#Returns a list containing a list of tuple\n",
    "#Each inner list corresponds to an article and each tuple refers to topicID and its corresponding probability  \n",
    "map(get_article_topic_distribution, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"percent\" + 0.009*\"government\" + 0.008*\"budget\" + 0.008*\"country\" + 0.006*\"increase\" + 0.005*\"european\" + 0.005*\"economic\" + 0.005*\"year\" + 0.005*\"market\" + 0.005*\"trade\"'),\n",
       " (1,\n",
       "  '0.021*\"trump\" + 0.012*\"president\" + 0.009*\"state\" + 0.008*\"party\" + 0.007*\"house\" + 0.007*\"russian\" + 0.006*\"election\" + 0.006*\"country\" + 0.005*\"russia\" + 0.005*\"order\"'),\n",
       " (2,\n",
       "  '0.013*\"people\" + 0.006*\"woman\" + 0.006*\"year\" + 0.005*\"child\" + 0.005*\"family\" + 0.005*\"think\" + 0.005*\"health\" + 0.004*\"school\" + 0.004*\"learn\" + 0.004*\"world\"'),\n",
       " (3,\n",
       "  '0.043*\"china\" + 0.020*\"korea\" + 0.019*\"chinese\" + 0.013*\"north\" + 0.011*\"japan\" + 0.011*\"missile\" + 0.010*\"south\" + 0.007*\"brand\" + 0.007*\"beijing\" + 0.007*\"system\"'),\n",
       " (4,\n",
       "  '0.012*\"police\" + 0.008*\"north\" + 0.008*\"attack\" + 0.008*\"force\" + 0.007*\"syrian\" + 0.007*\"people\" + 0.007*\"report\" + 0.007*\"group\" + 0.006*\"kill\" + 0.006*\"south\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()\n",
    "#lda_model.\n",
    "#a=lda_model.get_document_topics(corpus)\n",
    "#print(a)\n",
    "#https://humboldt-wi.github.io/blog/research/information_systems_1819/is_lda_final/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to interpret this?\n",
    "The top 10 keywords that contribute to the topic are showcased with their respective weight.\n",
    "\n",
    "Let's try to interpret the 5 topics:\n",
    "\n",
    "- Topic 1: key words like \"Russia\", \"Country\", \"Government\", \"Minister\" suggest **Politics in Russia**\n",
    "- Topic 2: key words like \"China\", \"Brexit\",\"Trade\", \"Business\", \"Market\" suggest **Inter country trade news**\n",
    "- Topic 3: key words like \"Player\",\"Sport\",\"World\" suggest **Sports news (football)**\n",
    "- Topic 4: key words like \"People\",\"Woman\",\"Police\", \"Family,\"Child\" suggest **Domestic news**\n",
    "- Topic 5: key words like \"Trump\", \"State\", \"White\", \"Committee\" suggest **Polictics in USA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Model Perplexity and Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.423501550211952\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "#coherence_model_lda = models.CoherenceModel(model=lda_model, texts=lemma_doc, dictionary=word2id, coherence='c_v')\n",
    "#coherence_lda = coherence_model_lda.get_coherence()\n",
    "#print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherence measures the relative distance between words within a topic. There are two major types C_V typically 0 < x < 1 and uMass -14 < x < 14.\n",
    "Coherence score of 0.4 is low. I want to explore what would have been the ideal number of topics. Will explore the elbow method below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42, update_every=1, chunksize=100, \n",
    "                     passes=10, alpha='auto', per_word_topics=False)\n",
    "        model_list.append(model)\n",
    "\n",
    "        #coherencemodel = models.CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        #coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11984/845464271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword2id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlemma_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11984/2558551836.py\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[1;34m(dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmodel_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42, update_every=1, chunksize=100, \n\u001b[0m\u001b[0;32m     21\u001b[0m                      passes=10, alpha='auto', per_word_topics=True)\n\u001b[0;32m     22\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m             self.add_lifecycle_event(\n\u001b[0;32m    522\u001b[0m                 \u001b[1;34m\"created\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1017\u001b[0m                         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reached the end of input; now waiting for all remaining jobs to finish\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m                         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpass_\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m                     \u001b[1;32mdel\u001b[0m \u001b[0mother\u001b[0m  \u001b[1;31m# frees up memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mdo_mstep\u001b[1;34m(self, rho, other, extra_pass)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m         \u001b[0mcurrent_Elogbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_Elogbeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_Elogbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=word2id, corpus=corpus, texts=lemma_doc, start=2, limit=100, step=10)\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/lets-build-an-article-recommender-using-lda-f22d71b7143e\n",
    "def get_similarity(lda, query_vector):\n",
    "    index = similarities.MatrixSimilarity(lda[corpus])\n",
    "    \n",
    "    sims = index[query_vector]\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inspired', 'by', 'erotic', 'arabic', 'poetry,', 'women', 'artists', 'depict', 'radical', 'love']\n",
      "[(680, 1), (1835, 1), (2460, 1), (2493, 1), (4700, 1)]\n",
      "Dictionary(30441 unique tokens: ['     ', 'account', 'activist', 'addition', 'additional']...)\n",
      "Top words identified: \n",
      "680 arabic\n",
      "1835 love\n",
      "2460 radical\n",
      "2493 depict\n",
      "4700 erotic\n",
      "from here!!!!\n",
      "[(0, 0.051980518), (1, 0.15822597), (2, 0.5722676), (3, 0.014561373), (4, 0.20296451)]\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/RaRe-Technologies/gensim/issues/2644\n",
    "# its taking me 3 days for this fucking issue!!!!\n",
    "query=\"Inspired By Erotic Arabic Poetry, Women Artists Depict Radical Love\"\n",
    "#query=\"Trump Says White House Could Mean Millions for Brand\"\n",
    "print(query.lower().split())\n",
    "#words = word2id.doc2bow(query.split())\n",
    "words = word2id.doc2bow(query.lower().split())\n",
    "print(words)\n",
    "print(word2id)\n",
    "\n",
    "\n",
    "print(\"Top words identified: \")\n",
    "for word in words:\n",
    "    print(\"{} {}\".format(word[0], word2id[word[0]]))\n",
    "\n",
    "print(\"from here!!!!\")\n",
    "query_vector = lda_model[words]\n",
    "print(query_vector)\n",
    "\n",
    "sims = get_similarity(lda_model, query_vector)\n",
    "\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2673\n",
      "(692, 0.9974572)\n",
      "689\n",
      "692\n",
      "(689, 0.9980267)\n",
      "(692, 0.9974572)\n",
      "(2439, 0.99565595)\n",
      "(81, 0.99429584)\n",
      "(2255, 0.9941871)\n",
      "(2651, 0.9938768)\n",
      "(17, 0.99250656)\n",
      "(728, 0.99131095)\n",
      "(54, 0.9908147)\n",
      "(674, 0.98875606)\n"
     ]
    }
   ],
   "source": [
    "print(len(sims))\n",
    "#print(sims)\n",
    "print(sims[1])\n",
    "print(sims[0][0])\n",
    "print(sims[1][0])\n",
    "for i in range(0,10):\n",
    "    print(sims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check out the links below:\n",
      "http://www.cnn.com/2017/02/09/health/dog-dna-death-penalty-eprise/index.html\n",
      "http://www.cnn.com/2017/02/09/tennis/andy-murray-roger-federer-andy-murray-live/index.html\n",
      "http://www.huffingtonpost.com/2017/03/15/rhythmic-gymnast-abuse-team-usa_n_15390974.html\n",
      "http://www.bbc.co.uk/news/uk-england-38891475\n",
      "http://www.huffingtonpost.com/2017/03/13/michael-brown-unedited-video_n_15346390.html\n",
      "http://www.huffingtonpost.com/2017/03/16/mischa-barton-takes-legal-action-over-revenge-porn_n_15401950.html\n",
      "http://abcnews.go.com/Sports/tom-brady-missing-super-bowl-jersey-shows-ebay/story?id=45299006\n",
      "http://www.bbc.co.uk/news/world-australia-38916464\n",
      "http://www.cnn.com/2016/04/21/us/project-vic-child-abuse/index.html\n",
      "http://abcnews.go.com/Entertainment/anna-nicole-smiths-daughter-now-10-fearless-mom/story?id=45329494\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "pids = []\n",
    "result = 10\n",
    "article_ids = df['article_source_link'].values.tolist()\n",
    "\n",
    "print(\"\\nCheck out the links below:\")\n",
    "while result > 0:\n",
    "    article_id = article_ids[sims[idx][0]]\n",
    "    \n",
    "    if article_id not in pids:\n",
    "        pids.append(article_id)\n",
    "        print(\"{}\".format(article_id))\n",
    "        result -= 1\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 2),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 3),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 2),\n",
       " (31, 2),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 2),\n",
       " (36, 3),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 9),\n",
       " (48, 1),\n",
       " (49, 6),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1),\n",
       " (53, 1),\n",
       " (54, 1),\n",
       " (55, 1),\n",
       " (56, 1),\n",
       " (57, 1),\n",
       " (58, 2),\n",
       " (59, 1),\n",
       " (60, 1),\n",
       " (61, 1),\n",
       " (62, 1),\n",
       " (63, 1),\n",
       " (64, 1),\n",
       " (65, 1),\n",
       " (66, 1),\n",
       " (67, 1),\n",
       " (68, 1),\n",
       " (69, 1),\n",
       " (70, 1),\n",
       " (71, 1),\n",
       " (72, 1),\n",
       " (73, 1),\n",
       " (74, 2),\n",
       " (75, 1),\n",
       " (76, 1),\n",
       " (77, 1),\n",
       " (78, 1),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (82, 2),\n",
       " (83, 1),\n",
       " (84, 3),\n",
       " (85, 1),\n",
       " (86, 1),\n",
       " (87, 2),\n",
       " (88, 1),\n",
       " (89, 1),\n",
       " (90, 1),\n",
       " (91, 1),\n",
       " (92, 2),\n",
       " (93, 1),\n",
       " (94, 1),\n",
       " (95, 1),\n",
       " (96, 4),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (99, 4),\n",
       " (100, 1),\n",
       " (101, 1),\n",
       " (102, 1),\n",
       " (103, 1),\n",
       " (104, 1),\n",
       " (105, 1),\n",
       " (106, 1),\n",
       " (107, 1),\n",
       " (108, 2),\n",
       " (109, 1),\n",
       " (110, 1),\n",
       " (111, 5),\n",
       " (112, 2),\n",
       " (113, 6),\n",
       " (114, 1),\n",
       " (115, 2),\n",
       " (116, 1),\n",
       " (117, 1),\n",
       " (118, 2),\n",
       " (119, 1),\n",
       " (120, 1),\n",
       " (121, 2),\n",
       " (122, 1),\n",
       " (123, 1),\n",
       " (124, 1),\n",
       " (125, 2),\n",
       " (126, 2),\n",
       " (127, 1),\n",
       " (128, 1),\n",
       " (129, 1),\n",
       " (130, 1),\n",
       " (131, 1),\n",
       " (132, 1),\n",
       " (133, 3),\n",
       " (134, 1),\n",
       " (135, 2),\n",
       " (136, 1),\n",
       " (137, 1),\n",
       " (138, 1),\n",
       " (139, 1),\n",
       " (140, 1),\n",
       " (141, 1)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(corpus))\n",
    "#doc_topic_dist =documents_topic_distribution()\n",
    "#doc_topic_dist\n",
    "corpus[0]\n",
    "#documents[0]\n",
    "#%%cache mycache_lda_index.pkl index\n",
    "#index = similarities.MatrixSimilarity(lda_model[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11984/1771047296.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Use this to get the graph of optimal # of topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword2id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlemma_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Show graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11984/2558551836.py\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[1;34m(dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmodel_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42, update_every=1, chunksize=100, \n\u001b[0m\u001b[0;32m     21\u001b[0m                      passes=10, alpha='auto', per_word_topics=True)\n\u001b[0;32m     22\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m             self.add_lifecycle_event(\n\u001b[0;32m    522\u001b[0m                 \u001b[1;34m\"created\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m                     )\n\u001b[1;32m-> 1005\u001b[1;33m                     \u001b[0mgammat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    716\u001b[0m                 \u001b[1;31m# Substituting the value of the optimal phi back into\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;31m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m                 \u001b[0mgammad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcts\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mphinorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m                 \u001b[0mElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Use this to get the graph of optimal # of topics\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=word2id, corpus=corpus, texts=lemma_doc, start=2, limit=100, step=10)\n",
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=100; start=2; step=10;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can decide on the number of topics based on this analysis. Note that the Customization used for 5 topic model (lda_model) and the optimization models is difference therefore the Coherence score for 5 topics LDA model differ.\n",
    "\n",
    "### Vizualize the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el762818055151077926803792773\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el762818055151077926803792773_data = {\"mdsDat\": {\"x\": [-0.00943684282586355, -0.034501032245662755, -0.20675419200840103, -0.010219464148878294, 0.2609115312288056], \"y\": [-0.02322786530303222, 0.22618978864053108, -0.0011893816874323287, -0.22123422866499326, 0.019461687014926805], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [32.38683325359569, 23.119621896054714, 19.863647053602705, 13.11806479313257, 11.511833003614317]}, \"tinfo\": {\"Term\": [\"trump\", \"police\", \"china\", \"president\", \"north\", \"garda\", \"percent\", \"court\", \"house\", \"committee\", \"woman\", \"family\", \"market\", \"arrest\", \"korea\", \"russia\", \"russian\", \"party\", \"attack\", \"force\", \"officer\", \"palestinian\", \"government\", \"child\", \"business\", \"death\", \"election\", \"minister\", \"syria\", \"company\", \"trump\", \"committee\", \"party\", \"election\", \"republican\", \"donald\", \"obama\", \"nune\", \"senate\", \"democratic\", \"putin\", \"parliament\", \"democrat\", \"congress\", \"vote\", \"conservative\", \"obamacare\", \"referendum\", \"repeal\", \"kushner\", \"candidate\", \"ukraine\", \"spicer\", \"politician\", \"lawmaker\", \"legislation\", \"independence\", \"representation\", \"speaker\", \"barack\", \"brexit\", \"campaign\", \"president\", \"administration\", \"presidential\", \"house\", \"intelligence\", \"political\", \"white\", \"britain\", \"leader\", \"prime\", \"washington\", \"minister\", \"russian\", \"issue\", \"state\", \"order\", \"government\", \"russia\", \"member\", \"union\", \"meeting\", \"official\", \"right\", \"european\", \"country\", \"report\", \"call\", \"people\", \"adult\", \"england\", \"disability\", \"patient\", \"sport\", \"treatment\", \"sugar\", \"doctor\", \"football\", \"award\", \"beach\", \"berry\", \"celebrate\", \"huffpost\", \"eat\", \"artist\", \"title\", \"honour\", \"culture\", \"afford\", \"jackson\", \"like\", \"character\", \"season\", \"gender\", \"stone\", \"charity\", \"score\", \"music\", \"marriage\", \"photo\", \"parent\", \"young\", \"wale\", \"school\", \"disease\", \"parmila\", \"student\", \"friend\", \"woman\", \"child\", \"family\", \"college\", \"learn\", \"daughter\", \"player\", \"davis\", \"heart\", \"people\", \"thing\", \"story\", \"start\", \"think\", \"india\", \"education\", \"year\", \"black\", \"ireland\", \"live\", \"world\", \"find\", \"health\", \"little\", \"work\", \"great\", \"place\", \"social\", \"take\", \"share\", \"twitter\", \"right\", \"follow\", \"go\", \"china\", \"market\", \"company\", \"chinese\", \"product\", \"technology\", \"growth\", \"investment\", \"environmental\", \"consumer\", \"customer\", \"samsung\", \"arctic\", \"sector\", \"industrial\", \"production\", \"euro\", \"premium\", \"bank\", \"electronic\", \"factory\", \"bonus\", \"good\", \"reduction\", \"provider\", \"carbon\", \"emission\", \"invest\", \"investor\", \"waste\", \"climate\", \"payment\", \"percent\", \"industry\", \"energy\", \"management\", \"infrastructure\", \"global\", \"economy\", \"development\", \"project\", \"business\", \"increase\", \"plant\", \"economic\", \"reduce\", \"financial\", \"trade\", \"price\", \"research\", \"service\", \"program\", \"level\", \"country\", \"european\", \"build\", \"provide\", \"change\", \"large\", \"year\", \"include\", \"world\", \"system\", \"government\", \"accord\", \"korea\", \"palestinian\", \"israel\", \"syrian\", \"israeli\", \"helicopter\", \"korean\", \"missile\", \"ireann\", \"mosul\", \"malaysian\", \"aircraft\", \"wreckage\", \"coast\", \"syria\", \"fighter\", \"humanitarian\", \"raqqa\", \"malaysia\", \"rebel\", \"pyongyang\", \"jerusalem\", \"plane\", \"rocket\", \"river\", \"saudi\", \"assad\", \"troop\", \"apartheid\", \"kuala\", \"drone\", \"settlement\", \"territory\", \"north\", \"turkey\", \"military\", \"turkish\", \"tillerson\", \"south\", \"civilian\", \"strike\", \"force\", \"resolution\", \"flight\", \"international\", \"jazeera\", \"region\", \"country\", \"government\", \"russia\", \"group\", \"russian\", \"state\", \"operation\", \"minister\", \"march\", \"water\", \"foreign\", \"report\", \"police\", \"garda\", \"arrest\", \"victim\", \"prison\", \"murder\", \"bailey\", \"asylum\", \"sullivan\", \"sentence\", \"suspect\", \"detain\", \"detention\", \"navalny\", \"masood\", \"inquest\", \"killing\", \"church\", \"assault\", \"guilty\", \"checkpoint\", \"convict\", \"wound\", \"funeral\", \"coroner\", \"offence\", \"conviction\", \"sergeant\", \"venezuela\", \"toscan\", \"hussein\", \"officer\", \"trial\", \"tribunal\", \"commissioner\", \"breath\", \"warrant\", \"crime\", \"incident\", \"death\", \"criminal\", \"kill\", \"attack\", \"violence\", \"abuse\", \"charge\", \"authority\", \"court\", \"lawyer\", \"investigation\", \"report\", \"find\", \"justice\", \"people\", \"accord\", \"woman\", \"family\", \"state\", \"release\", \"number\", \"protest\", \"group\"], \"Freq\": [5606.0, 1848.0, 2010.0, 3787.0, 1652.0, 1185.0, 1802.0, 1675.0, 3155.0, 1929.0, 1974.0, 1758.0, 1113.0, 821.0, 867.0, 1849.0, 2000.0, 1492.0, 1089.0, 1519.0, 788.0, 765.0, 3400.0, 1434.0, 1338.0, 878.0, 1334.0, 2034.0, 723.0, 900.0, 5605.904959588747, 1928.7418700386786, 1491.4516367980239, 1333.687726636089, 1274.4598985499183, 962.3897995348235, 866.8195448195569, 747.2908650672114, 660.8636519878211, 569.9579311165485, 521.2372819067737, 519.6143159852787, 506.5720559454132, 505.74843383235856, 491.6809965521678, 448.55197665886845, 402.45034955936825, 364.2715532940157, 357.22932756181143, 358.07848709368244, 344.4478978716526, 338.63734410891374, 332.2911502506205, 333.4226742135517, 313.01336926232614, 307.7460102803542, 301.6067631409148, 329.8272251820579, 271.8069844706154, 270.3918208199322, 942.6007213255481, 1321.9915242482007, 3561.938255850292, 1291.8381281969955, 565.6930853192644, 2866.867441210217, 901.5384243975261, 1307.9320613579562, 1469.0090561203247, 820.4003949462771, 1185.2881393598004, 663.7712372452276, 545.928801974276, 1463.1919485067392, 1431.372260091496, 1369.404212081856, 2268.566074565456, 911.6888865349804, 1848.164759821964, 1211.0075163209299, 1173.0150689574843, 752.3043995400368, 768.6305262738521, 999.2569862213686, 1169.718255986739, 1050.984755280473, 1268.12881406205, 1103.1205419110088, 910.3288494868624, 1023.6489339637159, 297.5834427604067, 291.556628985274, 272.37537491979987, 251.91575469850636, 251.60010418162994, 232.04890107286573, 241.131159304401, 221.00083337232556, 221.1048671364304, 219.7395219319333, 204.34310101723273, 202.37252083729084, 171.85058394368292, 159.4613357266527, 161.91303173348226, 154.70234414476116, 151.5048500416903, 156.40273384320477, 146.12065333446546, 144.29432378135837, 143.8334546673121, 137.49644097016588, 133.63095514826134, 132.077074674101, 134.85289093823863, 133.16437039985576, 130.78257567936424, 130.8056917328417, 128.00965180277535, 130.7546428211243, 370.0151879295898, 531.9899047250186, 815.8811766270521, 437.90369519048966, 944.1465569735819, 222.49141550064763, 172.10161091723853, 496.2381047753441, 633.1198961062112, 1523.9071344541296, 1129.1845037224543, 1328.7055913749102, 231.85576794411102, 692.9123916724254, 303.68995275979154, 321.2979554209481, 227.0235447969906, 236.64245039165874, 2347.6190067164134, 624.6930229322412, 420.22643655655173, 682.7546492579141, 813.2559488907526, 460.8941890873283, 335.06078811377967, 957.4316271653294, 328.2870238967688, 584.9676125695461, 393.5287084641324, 671.9205260483322, 587.5707613634414, 647.9470352293401, 352.5749437462621, 531.2461347570984, 456.0583936687333, 524.6575294370344, 429.09553389216194, 551.4548662863126, 489.30720670727715, 459.6186346548632, 550.5913906536249, 478.54305392477147, 456.51596707425784, 2009.8190560822, 1112.9038836599893, 899.4905135871588, 794.3068955331016, 629.1651531503318, 556.2608208633325, 457.9315784640381, 434.57628743955166, 421.73098628256116, 370.00971622966586, 333.7329291165979, 319.0913245268794, 301.0371849812393, 276.021802825068, 261.6434548921847, 247.19301087148366, 247.01254293839634, 238.58807250436058, 233.23030945861748, 218.9332453599808, 217.48371995140886, 242.34362326068506, 206.3712990551386, 196.5112234404177, 187.21573880398503, 200.72463682750566, 175.9800555768536, 176.2507970788399, 172.64494322553713, 177.8411088604918, 792.4347337888026, 555.091600925551, 1638.5832509325464, 665.2659473964609, 500.9297169204271, 431.12161557759424, 286.0856919613237, 613.0250944420721, 518.9791635869645, 770.3279070150464, 745.0476643066505, 1081.509987750301, 836.361587079256, 339.4827158774236, 816.8054688054533, 513.1061738988107, 496.3608327921955, 843.1800037954093, 433.53312179867976, 447.1170860866654, 945.3546348940189, 461.4964636807864, 615.0079843717808, 1023.397174768996, 700.6608692617807, 515.6221115308138, 621.6413788839878, 656.2899547613848, 556.5319781900494, 664.466059024177, 642.4949891243781, 589.7733635766867, 534.2467824080366, 565.9794368649333, 534.101520968808, 866.5389756927875, 764.3131608912239, 711.7557890970758, 704.4256619115322, 598.1228640133851, 441.36225457042286, 385.8043564960332, 382.01807087785403, 354.0540196001368, 275.4977271744558, 265.00989045674015, 264.50360869453147, 274.063514999851, 251.7744068036944, 720.5062147317619, 239.95150628210095, 234.08757714755347, 224.12608201804164, 222.1114164169228, 214.61255915653226, 209.41664576588053, 193.3295283872092, 199.1070459636237, 190.76286449736338, 181.12360811111907, 168.78561205761633, 155.97597471065404, 142.45784889394525, 144.12141523291046, 139.72102955700112, 141.93809801780242, 546.8664255499418, 251.02348408665054, 1464.190499179335, 483.3728132353573, 735.1154695452341, 332.1895938740053, 316.0763751832829, 646.8226815767898, 328.39567139899356, 555.070449770429, 917.2287698407017, 298.4237021539342, 264.0257297628713, 678.6396055873977, 493.78619059895533, 453.98451431198464, 976.3858505408725, 882.4364008707512, 637.6459519476828, 561.3931918481745, 568.1866467658947, 724.2465484408492, 378.77434209183826, 504.81888566733187, 468.3086423679612, 402.0982443888084, 402.86221776187784, 407.7579137567039, 1847.7698441757611, 1184.086278859562, 820.1136521794066, 526.1377281455968, 332.8847337524524, 291.6581911817516, 285.6959591191486, 280.64913800672974, 254.7019597904728, 251.15360340230035, 234.7893101014818, 224.34857599248622, 215.7601002594128, 224.60845309387608, 209.79867149086164, 175.749217004204, 161.4926181121539, 160.01913583291878, 157.99843816996136, 151.88437205593698, 147.8096170756134, 137.32158042259553, 137.5456765117919, 134.73555883286215, 125.36746327124848, 120.67305873498796, 114.62786934809164, 117.30013029210149, 112.09610453374337, 106.16945839763558, 120.686577026317, 751.6581724521221, 340.1715977064901, 388.8457777978838, 551.2870288070787, 195.10371503473883, 199.894973882389, 505.36853748479007, 327.52118527103414, 716.0625605257992, 305.9078014155509, 586.9794491422741, 784.7414478045213, 242.28337801836923, 280.77126165386346, 574.2942885012627, 727.9978576450752, 908.5095985211333, 318.4374213768733, 545.2261981374307, 680.1586213911329, 468.9085811587195, 390.561430282481, 688.2602320750336, 441.18093610351366, 449.721971585013, 428.63669619044833, 486.4107060570391, 357.808171077824, 375.3907401376176, 347.34023972736, 324.1715179287622], \"Total\": [5606.0, 1848.0, 2010.0, 3787.0, 1652.0, 1185.0, 1802.0, 1675.0, 3155.0, 1929.0, 1974.0, 1758.0, 1113.0, 821.0, 867.0, 1849.0, 2000.0, 1492.0, 1089.0, 1519.0, 788.0, 765.0, 3400.0, 1434.0, 1338.0, 878.0, 1334.0, 2034.0, 723.0, 900.0, 5606.80813281984, 1929.6542449777685, 1492.3592087012282, 1334.593482021328, 1275.3631822180603, 963.2977911166338, 867.725666131068, 748.189281336349, 661.7617218212314, 570.8720369198547, 522.1554194658291, 520.5321931534601, 507.4709527296508, 506.6562230749477, 492.58228453803264, 449.46125084781363, 403.3553553184982, 365.1734744304006, 358.13559969784586, 359.00374354480067, 345.3548452080646, 339.5485427761513, 333.1871446120765, 334.3463953452295, 313.917887815825, 308.6520671421995, 302.53287153565446, 330.89331849360855, 272.7103389125956, 271.29839507026793, 962.4431894163669, 1366.5527003412371, 3787.0716077043867, 1353.3324031041734, 580.5804606770297, 3155.7939687697944, 952.3719486655367, 1467.6595983230934, 1706.5614439696224, 916.1595441093791, 1419.0024775328905, 761.9866135102822, 601.5484472039426, 2034.812762325196, 2000.2777629764767, 2001.1671483844684, 4002.4203364004657, 1175.5091795513622, 3400.3874988042517, 1849.3737668253034, 1768.35982613409, 912.0606597886033, 954.1947681617701, 1549.2194735918836, 2117.2277215906984, 1752.2332323267058, 3564.909571732109, 2610.340161773836, 1627.9634351556929, 4726.183973638257, 298.47148022954417, 292.4299239152908, 273.25753071132976, 252.78341349193963, 252.47203807928514, 232.92598133389828, 242.0465736951012, 221.86905602096732, 221.9753253985635, 220.61692941021138, 205.22279733389453, 203.31025835309705, 172.7199466716984, 160.32802382826287, 162.8015560492164, 155.5736916230919, 152.37042667511392, 157.3291816521694, 146.99793718642903, 145.18727906810764, 144.731536124342, 138.36769304187754, 134.49689108448374, 132.93996800711892, 135.73533880951317, 134.04855800411858, 131.652766446327, 131.6797604202539, 128.87055130090963, 131.63663197150206, 374.4789972489191, 560.6641486890995, 878.5670805237297, 463.4130998283918, 1048.4040102563551, 232.0396492123676, 177.03894916759194, 559.960996669559, 732.0969900928924, 1974.3388260464033, 1434.9203780999467, 1758.0534414604945, 247.73109906001332, 862.617893431407, 343.1259070027255, 368.01009394314195, 244.34757211256112, 257.012965026758, 4726.183973638257, 948.0478439498442, 566.7060907967603, 1186.1341169738644, 1553.2008188809007, 676.9621308505776, 426.858854312777, 2378.088313168955, 421.64357937661885, 1099.097912229587, 571.3468945014129, 1559.253229440338, 1221.9932760533645, 1487.2873102048814, 483.0818041017454, 1199.945740719001, 868.9080176375663, 1216.0839852264066, 778.4185401556806, 1524.31666576321, 1171.2444493405098, 996.7630182650954, 2117.2277215906984, 1374.3773543136415, 1107.4318390043331, 2010.5862276107157, 1113.6792146904988, 900.2623075547945, 795.0720344103435, 629.9425101208145, 557.0390189635289, 458.7016099213379, 435.3394453317092, 422.49898554306765, 370.7826773090888, 334.50933314539884, 319.87779279034277, 301.81256480245173, 276.7898497869847, 262.4147753177208, 247.959732893324, 247.7909605761984, 239.35678984902154, 234.02507220366206, 219.72184061462872, 218.27094196024916, 243.2726472898979, 207.16822790060192, 197.28462723971742, 187.9883506441988, 201.5553809137021, 176.7435029088895, 177.02044957188645, 173.41120554815606, 178.6316845724071, 812.4307584585763, 578.5503025689198, 1802.911116254528, 713.275609382039, 531.5131895072295, 454.5290492711354, 294.8453309261863, 674.1663136607773, 572.50034038533, 899.0608250130097, 867.9385209680562, 1338.5190160220673, 1008.7448519560272, 359.0261952175109, 1012.0987151298438, 589.9232439932697, 577.0757980293394, 1132.0103750060484, 508.0990691005954, 542.6805605963572, 1699.9191027058378, 599.9751062063203, 1033.030522105125, 3564.909571732109, 1752.2332323267058, 793.8578251768367, 1366.3711747803725, 1640.8793913424734, 991.6385621999965, 2378.088313168955, 2354.1758727622214, 1559.253229440338, 1055.429557771134, 3400.3874988042517, 1616.7462725701077, 867.4412813871404, 765.2128247549836, 712.6548976314897, 705.3273244517308, 599.023927376233, 442.26978700532, 386.70586467089333, 382.9169491586522, 354.9953629649243, 276.3945665548741, 265.9091230289212, 265.4069001215739, 275.00530927535027, 252.68454990997225, 723.1563997884224, 240.8539603747508, 235.0037322877434, 225.0262038854242, 223.01821992163542, 215.51327060886302, 210.31257963048134, 194.23057661249132, 200.04082784644822, 191.67529457471602, 182.042920908093, 169.69307541992714, 156.87193906843459, 143.3599607503156, 145.03562248150527, 140.6190991035927, 142.85236886567165, 563.5618553599851, 256.05794205571596, 1652.235616169142, 519.7402844527309, 847.1930861723929, 355.51177224472076, 350.80895725033884, 869.0601935451169, 374.29994307613333, 754.2787623756273, 1519.5176642766596, 340.4481635744941, 287.5717126368486, 1429.6899850518869, 874.358946187519, 756.2312496514782, 3564.909571732109, 3400.3874988042517, 1849.3737668253034, 1845.19410634616, 2000.2777629764767, 4002.4203364004657, 712.0861498829674, 2034.812762325196, 1744.6077625227447, 916.2243021788279, 1093.7715834705243, 2610.340161773836, 1848.700678138209, 1185.0178221595565, 821.0462682916606, 527.079224472658, 333.8119981193726, 292.5871256730744, 286.62600017953724, 281.59117390216727, 255.6402636430084, 252.08725074186063, 235.72655965206718, 225.2796083927592, 216.69024131624857, 225.6262033364361, 210.78689884759478, 176.68091867531692, 162.41880613758482, 160.95552733216, 158.9523975609058, 152.81169908891556, 148.76362185565534, 138.24736414394027, 138.52337205745215, 135.7181520889196, 126.3205933698893, 121.60035827845957, 115.56312119776229, 118.25820564846146, 113.06407700776573, 107.10388738250789, 121.83180976552975, 788.1048010533376, 354.2792016577337, 414.18692799397957, 600.7028205976274, 203.53974477624323, 210.58191811024008, 585.4294528359461, 364.00975037153324, 878.0979739527801, 349.880686793529, 767.7896689398603, 1089.4507095398658, 266.44232517, 321.8857343779044, 793.0135637330186, 1093.584666530547, 1675.7178951450448, 401.9319290130591, 1049.2034579113601, 2610.340161773836, 1221.9932760533645, 845.0509041103335, 4726.183973638257, 1616.7462725701077, 1974.3388260464033, 1758.0534414604945, 4002.4203364004657, 922.4617985295937, 1484.7524789735285, 956.7692829993117, 1845.19410634616], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9014, -4.9683, -5.2254, -5.3372, -5.3827, -5.6635, -5.7681, -5.9165, -6.0394, -6.1874, -6.2767, -6.2799, -6.3053, -6.3069, -6.3351, -6.4269, -6.5354, -6.635, -6.6546, -6.6522, -6.691, -6.708, -6.7269, -6.7235, -6.7867, -6.8037, -6.8238, -6.7344, -6.9279, -6.9331, -5.6843, -5.3461, -4.3549, -5.3691, -6.1949, -4.572, -5.7288, -5.3567, -5.2406, -5.8232, -5.4552, -6.035, -6.2305, -5.2446, -5.2666, -5.3108, -4.806, -5.7176, -5.011, -5.4337, -5.4656, -5.9098, -5.8883, -5.6259, -5.4684, -5.5755, -5.3877, -5.5271, -5.7191, -5.6018, -6.5002, -6.5206, -6.5887, -6.6668, -6.668, -6.7489, -6.7105, -6.7977, -6.7972, -6.8034, -6.8761, -6.8858, -7.0493, -7.1241, -7.1088, -7.1544, -7.1753, -7.1434, -7.2114, -7.224, -7.2272, -7.2723, -7.3008, -7.3125, -7.2917, -7.3043, -7.3223, -7.3222, -7.3438, -7.3226, -6.2823, -5.9193, -5.4916, -6.1139, -5.3456, -6.791, -7.0478, -5.9888, -5.7452, -4.8668, -5.1666, -5.0039, -6.7498, -5.655, -6.4799, -6.4235, -6.7708, -6.7293, -4.4347, -5.7586, -6.1551, -5.6697, -5.4948, -6.0627, -6.3816, -5.3316, -6.402, -5.8243, -6.2207, -5.6857, -5.8199, -5.7221, -6.3306, -5.9207, -6.0733, -5.9331, -6.1342, -5.8833, -6.0029, -6.0655, -5.8849, -6.0251, -6.0723, -4.4383, -5.0294, -5.2423, -5.3666, -5.5997, -5.7229, -5.9174, -5.9697, -5.9997, -6.1306, -6.2337, -6.2786, -6.3369, -6.4236, -6.4771, -6.5339, -6.5346, -6.5693, -6.5921, -6.6553, -6.662, -6.5537, -6.7144, -6.7634, -6.8118, -6.7422, -6.8737, -6.8722, -6.8929, -6.8632, -5.369, -5.725, -4.6425, -5.5439, -5.8276, -5.9777, -6.3878, -5.6257, -5.7922, -5.3973, -5.4306, -5.058, -5.315, -6.2167, -5.3387, -5.8036, -5.8368, -5.3069, -5.9721, -5.9413, -5.1925, -5.9096, -5.6225, -5.1132, -5.4921, -5.7987, -5.6117, -5.5575, -5.7224, -5.5451, -5.5787, -5.6643, -5.7632, -5.7055, -5.7635, -4.8647, -4.9902, -5.0615, -5.0718, -5.2354, -5.5393, -5.6739, -5.6837, -5.7597, -6.0106, -6.0494, -6.0513, -6.0158, -6.1007, -5.0492, -6.1487, -6.1735, -6.217, -6.226, -6.2604, -6.2849, -6.3648, -6.3353, -6.3782, -6.43, -6.5006, -6.5795, -6.6701, -6.6585, -6.6895, -6.6738, -5.325, -6.1036, -4.3401, -5.4484, -5.0292, -5.8235, -5.8732, -5.1571, -5.835, -5.3101, -4.8078, -5.9307, -6.0531, -5.1091, -5.4271, -5.5111, -4.7453, -4.8465, -5.1714, -5.2988, -5.2867, -5.0441, -5.6922, -5.405, -5.4801, -5.6325, -5.6306, -5.6185, -3.9768, -4.4218, -4.7891, -5.233, -5.6908, -5.823, -5.8436, -5.8615, -5.9585, -5.9725, -6.0399, -6.0854, -6.1244, -6.0842, -6.1524, -6.3295, -6.4141, -6.4233, -6.436, -6.4755, -6.5026, -6.5762, -6.5746, -6.5953, -6.6673, -6.7055, -6.7569, -6.7338, -6.7792, -6.8335, -6.7054, -4.8763, -5.6691, -5.5354, -5.1863, -6.225, -6.2008, -5.2733, -5.707, -4.9248, -5.7753, -5.1236, -4.8332, -6.0085, -5.861, -5.1454, -4.9083, -4.6868, -5.7351, -5.1974, -4.9762, -5.3482, -5.531, -4.9644, -5.4091, -5.3899, -5.438, -5.3115, -5.6186, -5.5706, -5.6483, -5.7173], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1273, 1.1269, 1.1268, 1.1267, 1.1267, 1.1265, 1.1264, 1.1262, 1.1261, 1.1258, 1.1257, 1.1257, 1.1256, 1.1256, 1.1256, 1.1254, 1.1252, 1.1249, 1.1249, 1.1248, 1.1248, 1.1247, 1.1247, 1.1247, 1.1245, 1.1245, 1.1244, 1.1242, 1.1241, 1.1241, 1.1066, 1.0943, 1.0661, 1.0809, 1.1014, 1.0314, 1.0726, 1.0122, 0.9775, 1.017, 0.9474, 0.9894, 1.0304, 0.7976, 0.7928, 0.7481, 0.5597, 0.8733, 0.5177, 0.704, 0.7169, 0.9349, 0.9112, 0.6889, 0.5341, 0.6163, 0.0938, 0.2661, 0.5461, -0.4023, 1.4615, 1.4615, 1.4613, 1.4611, 1.461, 1.4607, 1.4607, 1.4606, 1.4606, 1.4605, 1.4602, 1.4599, 1.4594, 1.4591, 1.459, 1.4589, 1.4588, 1.4586, 1.4585, 1.4583, 1.4583, 1.4582, 1.458, 1.458, 1.458, 1.4579, 1.4579, 1.4578, 1.4578, 1.4578, 1.4525, 1.412, 1.3905, 1.4079, 1.3597, 1.4225, 1.4362, 1.3437, 1.3192, 1.2055, 1.2249, 1.1845, 1.3983, 1.2454, 1.3424, 1.3287, 1.391, 1.3819, 0.7648, 1.0473, 1.1654, 0.9122, 0.8175, 1.08, 1.2223, 0.5547, 1.2142, 0.8338, 1.0916, 0.6227, 0.7322, 0.6336, 1.1496, 0.6497, 0.8199, 0.6238, 0.8689, 0.4477, 0.5917, 0.6904, 0.1176, 0.4095, 0.5783, 1.6159, 1.6156, 1.6154, 1.6153, 1.615, 1.6149, 1.6146, 1.6145, 1.6145, 1.6142, 1.614, 1.6138, 1.6137, 1.6135, 1.6133, 1.6132, 1.6131, 1.6131, 1.6129, 1.6127, 1.6127, 1.6125, 1.6124, 1.6124, 1.6122, 1.6121, 1.612, 1.6119, 1.6119, 1.6118, 1.5914, 1.5749, 1.5207, 1.5466, 1.557, 1.5634, 1.5861, 1.5212, 1.5181, 1.4617, 1.4636, 1.4031, 1.4289, 1.5603, 1.4019, 1.4768, 1.4656, 1.3217, 1.4576, 1.4226, 1.0295, 1.3539, 1.0977, 0.3683, 0.6997, 1.1847, 0.8287, 0.6999, 1.0386, 0.3412, 0.3177, 0.6441, 0.9354, -0.1768, 0.5087, 2.0301, 2.03, 2.0299, 2.0299, 2.0297, 2.0291, 2.0288, 2.0288, 2.0285, 2.0279, 2.0278, 2.0278, 2.0277, 2.0276, 2.0275, 2.0274, 2.0273, 2.0272, 2.0271, 2.027, 2.0269, 2.0265, 2.0265, 2.0264, 2.0261, 2.0258, 2.0255, 2.0249, 2.0249, 2.0248, 2.0248, 2.0011, 2.0113, 1.9104, 1.9586, 1.8893, 1.9633, 1.9269, 1.7358, 1.9003, 1.7245, 1.5264, 1.8994, 1.9458, 1.2861, 1.4598, 1.5209, 0.7361, 0.6822, 0.9664, 0.8413, 0.7726, 0.3217, 1.3999, 0.6372, 0.716, 1.2076, 1.0324, 0.1746, 2.1613, 2.161, 2.1607, 2.16, 2.159, 2.1586, 2.1585, 2.1584, 2.1581, 2.1581, 2.1578, 2.1577, 2.1575, 2.1573, 2.1571, 2.1565, 2.1561, 2.156, 2.1558, 2.1557, 2.1554, 2.1551, 2.1547, 2.1545, 2.1542, 2.1541, 2.1537, 2.1537, 2.1532, 2.153, 2.1524, 2.1144, 2.1212, 2.0987, 2.0759, 2.1195, 2.1097, 2.0147, 2.0562, 1.9578, 2.0275, 1.8933, 1.8337, 2.0667, 2.0251, 1.8391, 1.7549, 1.5496, 1.9289, 1.5072, 0.8169, 1.204, 1.39, 0.2351, 0.8631, 0.6824, 0.7504, 0.0542, 1.2147, 0.7868, 1.1485, 0.4227]}, \"token.table\": {\"Topic\": [1, 5, 1, 2, 3, 4, 5, 1, 3, 2, 2, 4, 4, 3, 5, 2, 4, 5, 5, 1, 4, 5, 1, 3, 4, 5, 2, 5, 3, 1, 2, 2, 2, 4, 5, 3, 2, 5, 1, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 1, 3, 2, 1, 2, 3, 2, 1, 2, 3, 5, 2, 5, 2, 5, 3, 3, 5, 4, 5, 1, 3, 4, 1, 2, 1, 5, 1, 3, 1, 1, 3, 5, 5, 5, 1, 2, 3, 4, 5, 1, 5, 1, 5, 1, 5, 2, 3, 2, 5, 2, 4, 2, 4, 5, 1, 1, 5, 5, 1, 3, 4, 2, 2, 3, 2, 1, 4, 2, 1, 3, 4, 1, 3, 1, 2, 3, 1, 3, 3, 1, 3, 2, 3, 3, 1, 3, 3, 2, 5, 4, 1, 3, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 5, 5, 5, 2, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 1, 2, 4, 2, 1, 2, 5, 2, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 3, 2, 3, 1, 3, 5, 1, 3, 5, 1, 2, 3, 4, 5, 3, 1, 5, 3, 3, 4, 1, 2, 4, 4, 1, 2, 3, 4, 5, 2, 1, 4, 5, 4, 1, 5, 4, 5, 5, 4, 4, 4, 1, 1, 2, 3, 4, 5, 1, 1, 5, 1, 3, 4, 1, 2, 3, 1, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 4, 5, 4, 4, 1, 2, 3, 1, 2, 3, 4, 5, 3, 2, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 4, 5, 1, 3, 4, 4, 4, 5, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 1, 5, 3, 5, 1, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 3, 1, 1, 2, 3, 4, 5, 1, 2, 1, 3, 1, 2, 3, 4, 5, 1, 3, 2, 5, 1, 2, 3, 4, 5, 4, 3, 4, 1, 2, 3, 5, 1, 4, 1, 3, 1, 3, 4, 1, 5, 1, 3, 1, 4, 5, 3, 3, 1, 2, 3, 1, 2, 3, 1, 4, 5, 1, 2, 3, 4, 5, 3, 1, 4, 4, 4, 1, 2, 3, 5, 3, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 1, 3, 4, 5, 1, 1, 1, 2, 3, 1, 4, 1, 2, 3, 4, 5, 4, 4, 1, 4, 1, 4, 3, 4, 1, 2, 3, 5, 2, 2, 3, 1, 5, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 5, 1, 2, 4, 5, 2, 3, 5, 2, 5, 5, 1, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 4, 1, 2, 3, 1, 2, 3, 1, 4, 2, 5, 1, 3, 2, 2, 3, 5, 1, 5, 4, 1, 1, 4, 1, 4, 1, 2, 4, 5, 1, 1, 3, 4, 5, 5, 1, 5, 1, 1, 2, 1, 5, 1, 4, 3, 2, 3, 4, 1, 2, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 2, 5], \"Freq\": [0.12426770039158894, 0.8729805952509122, 0.18122818958736428, 0.03030778597194829, 0.3302930144698038, 0.1855578732976426, 0.27277007374753465, 0.954680459166208, 0.04507392260769248, 0.99842035081817, 0.9918224304792523, 0.998466881903268, 0.9928595302051582, 0.997307717115808, 0.9987256889994306, 0.9963124123551572, 0.9944417142185371, 0.9940082843950757, 0.99790059505781, 0.09270726900775327, 0.18633243176805853, 0.7205465957533298, 0.1088164489152299, 0.0658385237134164, 0.15910976564075632, 0.665700628657877, 0.9972036170938438, 0.9978159686171347, 0.9956198188766288, 0.9952141439320655, 0.9940416106310789, 0.9935553751015285, 0.7779082050411709, 0.02134504221149554, 0.19684872261712555, 0.9947686379702962, 0.03930436293311961, 0.9580438464947905, 0.9797980913261412, 0.019741424957790757, 0.8950406130377017, 0.03165387533913823, 0.07313136716283661, 0.10581239780723768, 0.15997826811332364, 0.6499904436730315, 0.0491271846962175, 0.03527079926907923, 0.17780845632459527, 0.014194792731795422, 0.808356091358034, 0.5589806136603864, 0.20086446227136964, 0.02702763406709561, 0.09705377687729787, 0.11671023801700377, 0.9673977444630477, 0.03219780692615287, 0.9960769474444514, 0.9972445245014824, 0.9958317108963283, 0.378455603304234, 0.2218322698916927, 0.39978562925535827, 0.996305557098925, 0.18536883443457725, 0.01261012479146784, 0.07692176122795383, 0.723821163030254, 0.9950417567063193, 0.9948668777613099, 0.7868032381664049, 0.212555347777461, 0.9997084295104257, 0.9986516512165611, 0.9940634077748192, 0.8763025644737653, 0.12022443719914462, 0.023386608399771414, 0.9748523080325768, 0.9972908913100696, 0.06054952348298516, 0.9364992965368372, 0.08157111689812088, 0.9172588859360125, 0.9996609522252645, 0.9985978447123672, 0.9987047961811956, 0.9989737694919337, 0.997889121156444, 0.9909773025209975, 0.9951271548230458, 0.989545700074236, 0.3556892466654933, 0.020477377765442437, 0.28696380074037825, 0.27377973560372354, 0.06283469341724802, 0.45711751495838593, 0.5424540745393901, 0.13494367189301293, 0.862614611467994, 0.12289903850959082, 0.8745838554403439, 0.9932112163916735, 0.998477372393142, 0.8859721571463424, 0.11366090173916893, 0.9290045243233692, 0.06548049510649298, 0.16626846243907992, 0.017082376277987664, 0.8153987610026111, 0.9990719612085823, 0.998472447652963, 0.9943199102577971, 0.9968146174370576, 0.05895040527345086, 0.8564492841614558, 0.0845326566185333, 0.9953980016285142, 0.9567330443463172, 0.03878647477079664, 0.9960830228579276, 0.9986527622832713, 0.994033218542752, 0.9950764841032964, 0.1472188411788316, 0.8072335116986941, 0.045450112041786936, 0.09257636417181438, 0.9065496793428616, 0.058567368926313694, 0.7848027436126035, 0.15461785396546815, 0.9995553087668094, 0.9967147525589194, 0.995793322545651, 0.05644262568124275, 0.942591848876754, 0.9985298224287905, 0.9988189662930758, 0.9968079522579874, 0.5998059964907914, 0.40006089775456205, 0.9941772278580232, 0.7559497161223606, 0.2440198857911909, 0.9964544474443263, 0.13862996901480296, 0.8595058078917783, 0.06464847356210007, 0.48118104372803605, 0.05892012780343298, 0.01145669151733419, 0.3837991658306954, 0.07998005015550631, 0.9180318800458116, 0.26339199992187107, 0.34852145846015536, 0.06621180108533223, 0.10113670715232065, 0.22119107175759337, 0.9956061539866546, 0.17702986041169377, 0.025666039241844078, 0.01711069282789605, 0.6034809739684877, 0.17637175684139006, 0.4278772707872347, 0.20388169099477207, 0.3684498720667854, 0.06419914387851314, 0.8646395335127407, 0.07102884003580176, 0.9947085037788528, 0.9991410912641789, 0.9945825544330418, 0.02373301613531936, 0.02076638911840444, 0.9092711806844229, 0.04746603227063872, 0.5318611757898857, 0.4126664810458026, 0.048761466031670336, 0.00722392089358079, 0.9943609697662595, 0.5434674726482939, 0.16645161770505104, 0.2593822028548675, 0.030584749542977577, 0.2773596227771539, 0.5247966306488887, 0.18068655923656915, 0.017263047060818708, 0.16746205666778308, 0.0688274472388623, 0.28343901500728336, 0.30403305433859645, 0.17559128271961721, 0.9984704437347447, 0.9946882398811412, 0.3429061732058649, 0.43569254948509895, 0.22120809997005797, 0.07781708598987513, 0.9221324689800203, 0.9971289311577942, 0.9915515885977972, 0.9084876986179254, 0.054502924367730445, 0.03675778620149263, 0.9917168327997019, 0.995728866610023, 0.9931724746834951, 0.09889844973453579, 0.9010747642479927, 0.29904307836354505, 0.1805302674779924, 0.2727068981667556, 0.13762778038322243, 0.1100172688865883, 0.09021111713585908, 0.8287526805008593, 0.05650586457960404, 0.02379194298088591, 0.9982386326056087, 0.6809834390895259, 0.30134625070339105, 0.01624906253792795, 0.9984193903821971, 0.0658931826376615, 0.9323184351924447, 0.027132869884253914, 0.9700000983620775, 0.9961460542517994, 0.9471089538744627, 0.0052500496334504584, 0.048300456627744216, 0.08183592332833876, 0.044065497176797794, 0.33293931200247223, 0.47492813623882063, 0.06574851959712687, 0.9942354141888446, 0.4794113059837961, 0.5194416734814491, 0.9992202743506264, 0.9976287256244126, 0.9971961240377591, 0.4667464056585716, 0.5322546731194238, 0.999081045210429, 0.9982906736618721, 0.6841007764419811, 0.020987752089527544, 0.13542097181576104, 0.07895392452727028, 0.08045304967652224, 0.9949455651205587, 0.1589736121601819, 0.5649853554469774, 0.2756305074144161, 0.993664351751648, 0.5372457419922763, 0.4626940200858591, 0.23443920552947567, 0.7645322980322345, 0.9912645205852396, 0.9994912838521649, 0.9981746729610784, 0.9955973327411476, 0.9972040861332261, 0.07361553168933456, 0.13613831202822144, 0.5616965911090321, 0.1744587257843134, 0.05445532481128858, 0.9970760257651723, 0.206502628949648, 0.791178747060097, 0.8350936793713479, 0.0007047204045327831, 0.16419985425613845, 0.18895967871893132, 0.803368450013616, 0.008114832828420364, 0.9978873715370289, 0.12681135474394914, 0.15101199496226003, 0.5953357493704482, 0.12681135474394914, 0.9901155174895949, 0.19872410673489316, 0.73072510080643, 0.006210128335465411, 0.06624136891163106, 0.05600800548312225, 0.6895985675109427, 0.07701100753929309, 0.1767752673061046, 0.9954343644120502, 0.9965810762016528, 0.017600635235148293, 0.033001191065903046, 0.9482342232936142, 0.4218713316600898, 0.12954201216736452, 0.06649059031599241, 0.26825514024038316, 0.11349255933246981, 0.9993901163983854, 0.9951637172573674, 0.9962668512516818, 0.8059151293414208, 0.013624052901740534, 0.1802566999307209, 0.6633265372038906, 0.06220453460565044, 0.0169648730742683, 0.1142301453667399, 0.1436359253621383, 0.11921721464503052, 0.8675708194465093, 0.012984053080151839, 0.7189850717902019, 0.03243541677249031, 0.2481800828804183, 0.9976053576090927, 0.9949544357103084, 0.9979933304593502, 0.9932447615679325, 0.997224598352602, 0.04055111713143285, 0.04902448489023971, 0.02420962216801961, 0.8860721713495177, 0.1609695914872159, 0.21215657455428039, 0.28354894567413347, 0.09092424623754873, 0.2525673506598576, 0.9984104539238723, 0.999163714801357, 0.9966397983796993, 0.995062857651416, 0.0456792040244957, 0.9541878174005768, 0.6448408485879711, 0.03614723475568206, 0.15491672038149454, 0.16330804273549215, 0.074429196535715, 0.1909881269595706, 0.5322389714535092, 0.20222272266307476, 0.7758340095209367, 0.027222245948103043, 0.1020834223053864, 0.036579892992763464, 0.057847272639718963, 0.9984150491003965, 0.9488746538259674, 0.04994077125399828, 0.9989775980036202, 0.005648474557162906, 0.9715376238320197, 0.005648474557162906, 0.005648474557162906, 0.016945423671488716, 0.9990892214868221, 0.9969008508860705, 0.03975453802007151, 0.9592942870060734, 0.21666528550553144, 0.4968067288740115, 0.06072552435555422, 0.0801915461001918, 0.14557198869902893, 0.09096399623998276, 0.9090853038861691, 0.9880393899742744, 0.010681506918640804, 0.3034329902233691, 0.4317136039763382, 0.033714776691485454, 0.13814835327242822, 0.09292121380824041, 0.9947969229199193, 0.9442207964647863, 0.0529209295953715, 0.029890484475948952, 0.8722586833436012, 0.09510608696892849, 0.999620988867211, 0.8912148303969695, 0.1083357477317417, 0.995973052606596, 0.998509380706323, 0.940568430962197, 0.025877514383575325, 0.03353514619095986, 0.974886408233534, 0.024113798083514975, 0.14564088875618308, 0.8541641313538306, 0.8714063846097213, 0.12729882425774544, 0.997567498700025, 0.9985038156567116, 0.9961294808551158, 0.15333969534456468, 0.07666984767228234, 0.7683652125417861, 0.033412504802361825, 0.10830260177317282, 0.8583557268192953, 0.5466312613637454, 0.08988582882845526, 0.36267886748225553, 0.24444309581815235, 0.1244171445781015, 0.45522037604458315, 0.13905445570493696, 0.03732514337343045, 0.9947424899425316, 0.9977872115796267, 0.9937589105093593, 0.9954396249516492, 0.997618380495025, 0.06950056709490796, 0.0406832587872632, 0.8696046565777509, 0.0203416293936316, 0.9985572761360084, 0.9967865288347382, 0.02776928354875338, 0.37157946081903326, 0.6003454633873349, 0.3002834376898194, 0.15501996963770462, 0.1322547992713284, 0.0249332818298406, 0.38809195196012763, 0.9968291348338341, 0.42255029292828455, 0.1605154784559848, 0.15630146828172264, 0.2605024471362044, 0.9973002824666409, 0.9989311419389656, 0.027640569957981077, 0.14741637310923242, 0.8236889847478361, 0.12042949378702908, 0.8753168085008455, 0.552609427917827, 0.2602459784467715, 0.0009446315007142341, 0.09871399182463746, 0.08785072956642377, 0.9942710164015686, 0.9964768825517428, 0.6548162527896364, 0.3449816426752998, 0.7154006440938616, 0.2839605631343909, 0.997255849545898, 0.9959157118331904, 0.007630646126624263, 0.900416242941663, 0.010492138424108361, 0.08107561509538279, 0.9948377759946976, 0.9929293799208032, 0.9971463917929341, 0.9988489485019849, 0.9956870062303389, 0.9893605213983913, 0.13059444984566185, 0.02647184794168821, 0.5559088067754524, 0.14177145230993018, 0.14471276874789554, 0.02839084982034442, 0.9706121782330248, 0.34322467886729646, 0.41750464668186066, 0.23906196538020652, 0.2453692841922814, 0.5511173974789986, 0.11947300225069199, 0.08221798004348696, 0.01956136079671615, 0.021862697361035698, 0.09665613570142098, 0.7444823785573734, 0.11851883306245667, 0.99739526225728, 0.9964370035540877, 0.9981303352130547, 0.12477509742118065, 0.5758202130990971, 0.19390724599237533, 0.10032592292648984, 0.005058449895453269, 0.5669069736040271, 0.027983067890546953, 0.10268786520548927, 0.18089054600674995, 0.12142652673933767, 0.9921777748322637, 0.24174788699974067, 0.7411249090502999, 0.015881248051077854, 0.11799351173522558, 0.06363695014933514, 0.7358022361016876, 0.08219772727622456, 0.8857759789521495, 0.026787580008633557, 0.08572025602762738, 0.9956761474491288, 0.997495450701371, 0.9969177862132312, 0.0027656534611118014, 0.9970180727308044, 0.998118144008156, 0.11464526373084429, 0.09569563336210969, 0.5059551308452136, 0.26150489908853736, 0.021792074924044783, 0.2506040959728905, 0.3614734473326248, 0.08331602143601334, 0.14104680794285723, 0.1626958528829237, 0.9981347465291351, 0.015621464297833164, 0.9802468846890311, 0.27108336529648436, 0.6592494292229678, 0.0696167397259454, 0.44553157041121966, 0.5234352120582682, 0.030903923959159744, 0.0969188479863627, 0.900775175402665, 0.9975689070169519, 0.9896933023675836, 0.25441462936986, 0.7446928213846943, 0.9960245682830423, 0.01693579519182882, 0.019758427723800293, 0.9596950608702999, 0.06035922022233253, 0.9391894666594942, 0.9905136640440061, 0.9998558657973136, 0.06926536402293079, 0.9293103006409881, 0.0646954666361025, 0.933864996660262, 0.44142889727774715, 0.4614938471540084, 0.0020064949876261234, 0.09530851191224086, 0.9983844937997188, 0.8245065631646671, 0.12279884983303553, 0.05262807849987237, 0.9905887260045235, 0.9979524435368559, 0.08632262154792844, 0.9082641049825515, 0.9988178938700998, 0.05394754703580421, 0.9451610240672897, 0.04748745803884728, 0.9497491607769456, 0.9076575669638292, 0.09143070729489122, 0.9964637596408545, 0.18117834203397964, 0.3787282209987406, 0.43875718974493866, 0.8607952589055147, 0.1312580925764706, 0.007617657158455882, 0.7719039811681144, 0.22792440388822277, 0.28584625817703746, 0.44252000901459737, 0.2058426407280707, 0.03916843770938997, 0.02666787248298892, 0.09042790313835622, 0.4309755383615275, 0.3783862613590792, 0.10068922548029735, 0.9962217779593534, 0.9963444004844877, 0.14339248803825777, 0.40242407933317503, 0.27921587113607965, 0.05382474624309969, 0.12110567904697431, 0.9287850843598279, 0.07056945493910458], \"Term\": [\"abuse\", \"abuse\", \"accord\", \"accord\", \"accord\", \"accord\", \"accord\", \"administration\", \"administration\", \"adult\", \"afford\", \"aircraft\", \"apartheid\", \"arctic\", \"arrest\", \"artist\", \"assad\", \"assault\", \"asylum\", \"attack\", \"attack\", \"attack\", \"authority\", \"authority\", \"authority\", \"authority\", \"award\", \"bailey\", \"bank\", \"barack\", \"beach\", \"berry\", \"black\", \"black\", \"black\", \"bonus\", \"breath\", \"breath\", \"brexit\", \"brexit\", \"britain\", \"britain\", \"britain\", \"build\", \"build\", \"build\", \"build\", \"build\", \"business\", \"business\", \"business\", \"call\", \"call\", \"call\", \"call\", \"call\", \"campaign\", \"campaign\", \"candidate\", \"carbon\", \"celebrate\", \"change\", \"change\", \"change\", \"character\", \"charge\", \"charge\", \"charge\", \"charge\", \"charity\", \"checkpoint\", \"child\", \"child\", \"china\", \"chinese\", \"church\", \"civilian\", \"civilian\", \"climate\", \"climate\", \"coast\", \"college\", \"college\", \"commissioner\", \"commissioner\", \"committee\", \"company\", \"congress\", \"conservative\", \"consumer\", \"convict\", \"conviction\", \"coroner\", \"country\", \"country\", \"country\", \"country\", \"country\", \"court\", \"court\", \"crime\", \"crime\", \"criminal\", \"criminal\", \"culture\", \"customer\", \"daughter\", \"daughter\", \"davis\", \"davis\", \"death\", \"death\", \"death\", \"democrat\", \"democratic\", \"detain\", \"detention\", \"development\", \"development\", \"development\", \"disability\", \"disease\", \"disease\", \"doctor\", \"donald\", \"drone\", \"eat\", \"economic\", \"economic\", \"economic\", \"economy\", \"economy\", \"education\", \"education\", \"education\", \"election\", \"electronic\", \"emission\", \"energy\", \"energy\", \"england\", \"environmental\", \"euro\", \"european\", \"european\", \"factory\", \"family\", \"family\", \"fighter\", \"financial\", \"financial\", \"find\", \"find\", \"find\", \"find\", \"find\", \"flight\", \"flight\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"football\", \"force\", \"force\", \"force\", \"force\", \"force\", \"foreign\", \"foreign\", \"foreign\", \"friend\", \"friend\", \"friend\", \"funeral\", \"garda\", \"gender\", \"global\", \"global\", \"global\", \"global\", \"go\", \"go\", \"go\", \"go\", \"good\", \"government\", \"government\", \"government\", \"government\", \"great\", \"great\", \"great\", \"great\", \"group\", \"group\", \"group\", \"group\", \"group\", \"growth\", \"guilty\", \"health\", \"health\", \"health\", \"heart\", \"heart\", \"helicopter\", \"honour\", \"house\", \"house\", \"house\", \"huffpost\", \"humanitarian\", \"hussein\", \"incident\", \"incident\", \"include\", \"include\", \"include\", \"include\", \"include\", \"increase\", \"increase\", \"increase\", \"increase\", \"independence\", \"india\", \"india\", \"india\", \"industrial\", \"industry\", \"industry\", \"infrastructure\", \"infrastructure\", \"inquest\", \"intelligence\", \"intelligence\", \"intelligence\", \"international\", \"international\", \"international\", \"international\", \"international\", \"invest\", \"investigation\", \"investigation\", \"investment\", \"investor\", \"ireann\", \"ireland\", \"ireland\", \"israel\", \"israeli\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"jackson\", \"jazeera\", \"jazeera\", \"jazeera\", \"jerusalem\", \"justice\", \"justice\", \"kill\", \"kill\", \"killing\", \"korea\", \"korean\", \"kuala\", \"kushner\", \"large\", \"large\", \"large\", \"large\", \"large\", \"lawmaker\", \"lawyer\", \"lawyer\", \"leader\", \"leader\", \"leader\", \"learn\", \"learn\", \"learn\", \"legislation\", \"level\", \"level\", \"level\", \"level\", \"like\", \"little\", \"little\", \"little\", \"little\", \"live\", \"live\", \"live\", \"live\", \"malaysia\", \"malaysian\", \"management\", \"management\", \"management\", \"march\", \"march\", \"march\", \"march\", \"march\", \"market\", \"marriage\", \"masood\", \"meeting\", \"meeting\", \"meeting\", \"member\", \"member\", \"member\", \"member\", \"member\", \"military\", \"military\", \"military\", \"minister\", \"minister\", \"minister\", \"missile\", \"mosul\", \"murder\", \"music\", \"navalny\", \"north\", \"north\", \"north\", \"north\", \"number\", \"number\", \"number\", \"number\", \"number\", \"nune\", \"obama\", \"obamacare\", \"offence\", \"officer\", \"officer\", \"official\", \"official\", \"official\", \"official\", \"operation\", \"operation\", \"operation\", \"operation\", \"order\", \"order\", \"order\", \"order\", \"order\", \"palestinian\", \"parent\", \"parent\", \"parliament\", \"parmila\", \"parmila\", \"parmila\", \"parmila\", \"parmila\", \"party\", \"patient\", \"payment\", \"payment\", \"people\", \"people\", \"people\", \"people\", \"people\", \"percent\", \"percent\", \"photo\", \"photo\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plane\", \"plant\", \"plant\", \"player\", \"player\", \"player\", \"police\", \"political\", \"political\", \"politician\", \"premium\", \"president\", \"president\", \"president\", \"presidential\", \"presidential\", \"price\", \"price\", \"prime\", \"prime\", \"prison\", \"product\", \"production\", \"program\", \"program\", \"program\", \"project\", \"project\", \"project\", \"protest\", \"protest\", \"protest\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provider\", \"putin\", \"pyongyang\", \"raqqa\", \"rebel\", \"reduce\", \"reduce\", \"reduce\", \"reduce\", \"reduction\", \"referendum\", \"region\", \"region\", \"region\", \"release\", \"release\", \"release\", \"release\", \"release\", \"repeal\", \"report\", \"report\", \"report\", \"report\", \"representation\", \"republican\", \"research\", \"research\", \"research\", \"resolution\", \"resolution\", \"right\", \"right\", \"right\", \"right\", \"right\", \"river\", \"rocket\", \"russia\", \"russia\", \"russian\", \"russian\", \"samsung\", \"saudi\", \"school\", \"school\", \"school\", \"school\", \"score\", \"season\", \"sector\", \"senate\", \"sentence\", \"sergeant\", \"service\", \"service\", \"service\", \"service\", \"service\", \"settlement\", \"settlement\", \"share\", \"share\", \"share\", \"social\", \"social\", \"social\", \"social\", \"south\", \"south\", \"south\", \"south\", \"south\", \"speaker\", \"spicer\", \"sport\", \"start\", \"start\", \"start\", \"start\", \"start\", \"state\", \"state\", \"state\", \"state\", \"state\", \"stone\", \"story\", \"story\", \"story\", \"strike\", \"strike\", \"strike\", \"strike\", \"student\", \"student\", \"student\", \"sugar\", \"sullivan\", \"suspect\", \"syria\", \"syria\", \"syrian\", \"system\", \"system\", \"system\", \"system\", \"system\", \"take\", \"take\", \"take\", \"take\", \"take\", \"technology\", \"territory\", \"territory\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"tillerson\", \"tillerson\", \"title\", \"toscan\", \"trade\", \"trade\", \"treatment\", \"trial\", \"trial\", \"trial\", \"tribunal\", \"tribunal\", \"troop\", \"trump\", \"turkey\", \"turkey\", \"turkish\", \"turkish\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"ukraine\", \"union\", \"union\", \"union\", \"venezuela\", \"victim\", \"violence\", \"violence\", \"vote\", \"wale\", \"wale\", \"warrant\", \"warrant\", \"washington\", \"washington\", \"waste\", \"water\", \"water\", \"water\", \"white\", \"white\", \"white\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"wound\", \"wreckage\", \"year\", \"year\", \"year\", \"year\", \"year\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 3, 2, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el762818055151077926803792773\", ldavis_el762818055151077926803792773_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el762818055151077926803792773\", ldavis_el762818055151077926803792773_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el762818055151077926803792773\", ldavis_el762818055151077926803792773_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.009437 -0.023228       1        1  32.386833\n",
       "3     -0.034501  0.226190       2        1  23.119622\n",
       "2     -0.206754 -0.001189       3        1  19.863647\n",
       "1     -0.010219 -0.221234       4        1  13.118065\n",
       "4      0.260912  0.019462       5        1  11.511833, topic_info=           Term         Freq        Total Category  logprob  loglift\n",
       "128       trump  5606.000000  5606.000000  Default  30.0000  30.0000\n",
       "721      police  1848.000000  1848.000000  Default  29.0000  29.0000\n",
       "2376      china  2010.000000  2010.000000  Default  28.0000  28.0000\n",
       "96    president  3787.000000  3787.000000  Default  27.0000  27.0000\n",
       "632       north  1652.000000  1652.000000  Default  26.0000  26.0000\n",
       "...         ...          ...          ...      ...      ...      ...\n",
       "118       state   486.410706  4002.420336   Topic5  -5.3115   0.0542\n",
       "1160    release   357.808171   922.461799   Topic5  -5.6186   1.2147\n",
       "969      number   375.390740  1484.752479   Topic5  -5.5706   0.7868\n",
       "544     protest   347.340240   956.769283   Topic5  -5.6483   1.1485\n",
       "224       group   324.171518  1845.194106   Topic5  -5.7173   0.4227\n",
       "\n",
       "[349 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "1359      1  0.124268   abuse\n",
       "1359      5  0.872981   abuse\n",
       "580       1  0.181228  accord\n",
       "580       2  0.030308  accord\n",
       "580       3  0.330293  accord\n",
       "...     ...       ...     ...\n",
       "478       3  0.279216    year\n",
       "478       4  0.053825    year\n",
       "478       5  0.121106    year\n",
       "2955      2  0.928785   young\n",
       "2955      5  0.070569   young\n",
       "\n",
       "[611 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 3, 2, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim_models.prepare(lda_model,corpus,word2id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
